--
-- PGQueue v1.0
-- ------------
--
--   Copyright 2024 Fabian Thylmann
--
--   Licensed under the Apache License, Version 2.0 (the "License");
--   you may not use this file except in compliance with the License.
--   You may obtain a copy of the License at
--
--    http://www.apache.org/licenses/LICENSE-2.0
--
--   Unless required by applicable law or agreed to in writing, software
--   distributed under the License is distributed on an "AS IS" BASIS,
--   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
--   See the License for the specific language governing permissions and
--   limitations under the License.
--
-- Based on an idea by Rodrigo Mansueli: https://github.com/mansueli/supa_queue
--

-- create our schema
create schema if not exists pgqueue;

-- create tables
create type pgqueue.job_status as enum (
    'new',                  -- Newly created job, ready for first processing
    'failed',               -- Job has failed but will be retried later
    'processing',           -- Job is currently being processed
    'redirected',           -- Job has completed with http status 201 and a new job was created
    'completed',            -- Job has completed with http status 2xx (content set)
    'server_error',         -- Job has failed with a 500 server error and will not retry
    'too_many',             -- Job has been retried too many times and is nolonger queued
    'other'                 -- Job returned some other unexpected status in success result
);
create type pgqueue.job_type as enum ('FUNC', 'GET', 'POST', 'DELETE');
create type pgqueue.signing_styles as enum ('HMAC', 'HMAC_WITH_PREFIX');
create type pgqueue.signing_algs as enum ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512');
create type pgqueue.signing_encs as enum ('hex', 'base64');

CREATE TABLE pgqueue.job_queue (
    job_id BIGINT GENERATED BY DEFAULT AS IDENTITY,
    job_owner text,
    run_at timestamp with time zone not null default now(),
    job_type pgqueue.job_type NOT NULL DEFAULT 'POST',
    url TEXT NOT NULL,
    payload jsonb,
    headers jsonb,
    job_jwt TEXT,
    signing_secret BYTEA,
    signing_vault TEXT,
    signing_header TEXT,
    signing_style pgqueue.signing_styles,
    signing_alg pgqueue.signing_algs,
    signing_enc pgqueue.signing_encs,
    retry_limit INTEGER DEFAULT 10,
    job_status pgqueue.job_status NOT NULL DEFAULT 'new',
    created_at timestamp with time zone not null default now(),
    last_at timestamp with time zone,
    retry_count INTEGER DEFAULT 0,
    response_status SMALLINT,
    response_content TEXT,
    response_headers jsonb,
    CONSTRAINT job_id_pkey PRIMARY KEY (job_id)
);
-- index used for failed/scheduled job lookups
create index job_queue_status_run_idx on pgqueue.job_queue (run_at)
    where job_status = 'new' OR (job_status = 'failed' AND retry_count <= retry_limit);

-- index used to find completed specific kind of jobs
create index job_queue_status_idx on pgqueue.job_queue (job_status);

-- index used to lookup jobs from a specific owner, if one was set
create index job_queue_owner_idx on pgqueue.job_queue (job_owner)
    WHERE job_owner is not null;

CREATE TABLE pgqueue.executed_requests (
    request_id BIGINT NOT NULL,
    job_id BIGINT NOT NULL,
    checked SMALLINT NOT NULL DEFAULT 0,
    CONSTRAINT executed_requests_pkey PRIMARY KEY (request_id, job_id)
);

CREATE TABLE pgqueue.workers (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY,
    locked BOOLEAN NOT NULL DEFAULT FALSE,
    CONSTRAINT workers_pkey PRIMARY KEY (id)
);

--
-- Logging Table
--
CREATE TABLE pgqueue.failed_log (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY,
    job_id BIGINT NOT NULL,
    created_at timestamp with time zone not null default now(),
    job_run INTEGER NOT NULL, -- 1-based index of which time running this job it was
    response_status SMALLINT,
    response_content TEXT,
    response_headers jsonb,
    CONSTRAINT id_pkey PRIMARY KEY (id)
);

do $$
begin
execute (
    select string_agg('INSERT INTO pgqueue.workers DEFAULT VALUES',';')
    from generate_series(1,5)
);
end;
$$;

--
-- Execute process_job_results function if there are available workers
--
CREATE OR REPLACE FUNCTION pgqueue.process_job_results_if_unlocked()
RETURNS VOID
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
    _worker RECORD;
BEGIN
    -- Find an unlocked worker
    SELECT * INTO _worker FROM pgqueue.workers FOR UPDATE SKIP LOCKED LIMIT 1;
    IF _worker IS NOT NULL THEN
        RAISE LOG 'Using worker_id: %', _worker.id;
        -- Lock the worker (this is already done by the SELECT ... FOR UPDATE)

        -- Process executed requests
        PERFORM pgqueue.process_job_results();

        -- Unlock the worker
        UPDATE pgqueue.workers SET locked = FALSE WHERE id = _worker.id;
    ELSE
        RAISE NOTICE 'No unlocked workers available';
    END IF;
END;
$$ LANGUAGE plpgsql;

--
-- Loop through records in executed_requests and get response from pg_net
-- Adds logging into failed_log
--
CREATE OR REPLACE FUNCTION pgqueue.process_job_results()
RETURNS VOID
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
    _executed_request RECORD;
    _response_result RECORD;
    _retry_after_value TEXT;
    _retry_after_seconds INTEGER default 600; -- default 10 minutes from now
    _elem jsonb;
    _new_job_url text;
    _new_job_payload jsonb;
    _new_job_headers jsonb;
    _new_job_type text;
    _new_job_jwt text;
    _retry INTEGER;
BEGIN
    FOR _executed_request IN SELECT * FROM pgqueue.executed_requests
    FOR UPDATE SKIP LOCKED
    LOOP
        RAISE LOG 'Processing job_id: %, request_id: %', _executed_request.job_id, _executed_request.request_id;

        SELECT
            status,
            message,
            (response).status_code AS status_code,
            (response).headers AS headers,
            (response).body AS body
        INTO _response_result
        FROM net._http_collect_response(_executed_request.request_id);

        IF _response_result.status = 'ERROR' THEN
            -- Internal error/failure when trying to execute
            -- This does NOT mean http status was bad!
            RAISE NOTICE 'Job failed (job_id: %)', _executed_request.job_id;

            UPDATE pgqueue.job_queue
            SET job_status = 'failed',
                last_at = now(),
                response_status = 0,
                response_content = _response_result.message,
                retry_count = retry_count + 1,
                run_at = now() + 
                    INTERVAL '1 second' * 
                    ROUND((POWER(2, retry_count) * (10-(retry_count/1.5)))/2)
            WHERE job_id = _executed_request.job_id
            RETURNING retry_count INTO _retry;

            -- Log
            INSERT INTO pgqueue.failed_log
                (job_id, job_run, response_status, response_content)
            VALUES
                (_executed_request.job_id, _retry, 0, _response_result.message);
        ELSIF _response_result.status = 'SUCCESS'
            AND _response_result.status_code = 210 THEN
            -- 210 header we "misuse" to tell us the response
            -- represents a NEW job to put in our queue!
            RAISE LOG 'Job completed with new job request (job_id: %)', _executed_request.job_id;

            _elem := _response_result.body::jsonb;
            -- our body should be json of the form below:
            -- {
            --   'url': string
            --   'payload': json (optional)
            --   'headers': json (optional)
            --   'job_type': 'FUNC', 'GET', 'POST', 'DELETE' (default: POST)
            --   'jwt': string (optional)
            -- }

            _new_job_payload := null;
            IF _elem ? 'payload' THEN
                _new_job_payload = _elem->payload;
            END IF;
            
            _new_job_headers := '{}'::JSONB;
            IF _elem ? 'headers' THEN
                _new_job_headers = _elem->headers;
            END IF;
            
            _new_job_type := 'POST';
            IF _elem ? 'job_type' THEN
                _new_job_type = _elem->>job_type;
            END IF;

            _new_job_jwt := null;
            IF _elem ? 'jwt' THEN
                _new_job_jwt = _elem->>jwt;
            END IF;

            IF _elem ? 'url' THEN
                -- Insert new job since we have at least a url in json reply
                INSERT INTO pgqueue.job_queue
                    (job_owner, url, payload, headers, job_type, jwt)
                VALUES
                    (
                        'pgqueue', 
                        _elem->>url, 
                        _new_job_payload, 
                        _new_job_headers, 
                        _new_job_type, 
                        _new_job_jwt
                    );
            END IF;

            -- Mark this job as done, but status redirected        
            UPDATE pgqueue.job_queue
            SET job_status = 'redirected',
                last_at = now(),
                response_status = _response_result.status_code,
                response_content = _response_result.body::TEXT,
                response_headers = _response_result.headers
            WHERE job_id = _executed_request.job_id;
        ELSIF _response_result.status = 'SUCCESS' 
            AND _response_result.status_code BETWEEN 200 AND 299 THEN
            -- Successful result, store status, content, headers
            RAISE LOG 'Job completed (job_id: %)', _executed_request.job_id;

            UPDATE pgqueue.job_queue
            SET job_status = 'completed',
                last_at = now(),
                response_status = _response_result.status_code,
                response_content = _response_result.body::TEXT,
                response_headers = _response_result.headers
            WHERE job_id = _executed_request.job_id;
        ELSIF _response_result.status = 'SUCCESS' 
            AND _response_result.status_code = 429 THEN
            -- Error 429 means we need to slow down, the header retry-after should
            -- tell us when we can try again, so mark the job id with that time
            -- for earliest retry
            RAISE NOTICE 'Job returned error 429 Too Many Requests (job_id: %)', executed_request.job_id;

            -- find first retry-after in headers, case in-sensetive
            IF EXISTS (
                SELECT value INTO _retry_after_value
                    FROM jsonb_each_text(_response_result.headers) 
                    WHERE LOWER(key) = 'retry-after'
            ) THEN
                _retry_after_seconds := COALESCE(_retry_after_value::INTEGER, 600);
            END IF;

            -- set run_at to now() + retry-after seconds
            UPDATE pgqueue.job_queue
                SET job_status = 'failed',
                    last_at = now(),
                    response_status = 429,
                    response_headers = _response_result.headers,
                    retry_count = retry_count + 1,
                    run_at = now() + (_retry_after_seconds || ' seconds')::interval
                WHERE job_id = _executed_request.job_id;
        ELSIF _response_result.status = 'SUCCESS' 
            AND (
                _response_result.status_code BETWEEN 400 AND 499
                OR _response_result.status_code = 503 -- supabase boot error
                OR _response_result.status_code = 504 -- supabase invocation time limit
                OR _response_result.status_code = 546 -- supabase resource limit
            ) THEN
            -- General error codes, we retry, unless x-job-finished header
            -- is present in reply. Either way we store latest data
            RAISE NOTICE 'Job returned error % (job_id: %)', _response_result.status_code, _executed_request.job_id;

            IF EXISTS (
                SELECT 1
                FROM jsonb_each_text(_response_result.headers)
                WHERE LOWER(key) = 'x-job-finished'
            ) THEN
                UPDATE pgqueue.job_queue
                SET job_status = 'completed',
                    last_at = now(),
                    response_status = _response_result.status_code,
                    response_content = _response_result.body::TEXT,
                    response_headers = _response_result.headers
                WHERE job_id = _executed_request.job_id;
            ELSE
                UPDATE pgqueue.job_queue
                SET job_status = 'failed',
                    last_at = now(),
                    response_status = _response_result.status_code,
                    response_content = _response_result.body::TEXT,
                    response_headers = _response_result.headers,
                    retry_count = retry_count + 1,
                    run_at = now() + 
                        INTERVAL '1 second' * 
                        ROUND((POWER(2, retry_count) * (10-(retry_count/1.5)))/2)
                WHERE job_id = _executed_request.job_id
                RETURNING retry_count INTO _retry;

                -- Log
                INSERT INTO pgqueue.failed_log
                    (
                        job_id, 
                        job_run, 
                        response_status, 
                        response_content, 
                        response_headers
                    )
                VALUES
                    (
                        _executed_request.job_id,
                        _retry,
                        _response_result.status_code, 
                        _response_result.body::TEXT,
                        _response_result.headers
                    );
            END IF;
        ELSIF _response_result.status = 'SUCCESS' 
            AND _response_result.status_code = 500 THEN
            -- Server Errors are likely not recoverable, mark as such
            RAISE WARNING 'Job returned 500 Server Error (job_id: %)', _executed_request.job_id;

            UPDATE pgqueue.job_queue
            SET job_status = 'server_error',
                last_at = now(),
                response_status = 500,
                response_content = _response_result.body::TEXT,
                response_headers = _response_result.headers
            WHERE job_id = _executed_request.job_id;
        ELSIF _response_result.status = 'SUCCESS' THEN
            -- Unhandled special error (likely 1xx)
            RAISE WARNING 'Job returned error % (job_id: %)', _response_result.status_code, _executed_request.job_id;

            UPDATE pgqueue.job_queue
            SET job_status = 'other',
                last_at = now(),
                response_status = _response_result.status_code,
                response_content = _response_result.body::TEXT,
                response_headers = _response_result.headers
            WHERE job_id = _executed_request.job_id;
        ELSIF _response_result.status = 'PENDING' THEN
            -- TODO: decide how often it is ok to see this pending!
            RAISE LOG 'Job still in progress (job_id: %)', _executed_request.job_id;
        ELSE
            -- Job was not found, this should really not happen, log it and remove
            RAISE WARNING 'Job not found (job_id: %)', _executed_request.job_id;
        END IF;

        -- unlock the pgqueue.executed_requests row somehow
        IF _response_result.status = 'PENDING' THEN
            -- For still pending requests, we will update checked counter to unlock
            -- the row and keep track of all tries
            UPDATE pgqueue.executed_requests
                SET checked = checked + 1
                WHERE request_id = _executed_request.request_id;
        ELSE
            -- remove until next run
            DELETE FROM pgqueue.executed_requests
                WHERE request_id = _executed_request.request_id;
        END IF;
    END LOOP;
END;
$$ LANGUAGE plpgsql;

--
-- Create signature string for signing payloads!
--
CREATE OR REPLACE FUNCTION pgqueue.create_signature(
    _subject BYTEA,
    _signing_secret BYTEA DEFAULT NULL,
    _signing_vault TEXT DEFAULT NULL,
    _style pgqueue.signing_styles DEFAULT 'HMAC'::pgqueue.signing_styles,
    _alg pgqueue.signing_algs DEFAULT 'sha256'::pgqueue.signing_algs,
    _encoding pgqueue.signing_encs DEFAULT 'hex'::pgqueue.signing_encs
)
RETURNS TEXT
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
    _secret BYTEA;
    _hmac_sig BYTEA;
    _encoded_sig TEXT;
BEGIN
    -- Determine which secret to use
    IF _signing_vault IS NOT NULL THEN
        -- Load the secret from the vault using the provided key name
        SELECT decrypted_secret::BYTEA INTO _secret
            FROM vault.decrypted_secrets
            WHERE name = _signing_vault;

        -- Check if _secret is ok now
        IF _secret IS NULL THEN
            RAISE EXCEPTION 'Secret not found in vault for name: %', _signing_vault;
        END IF;
    ELSE
        -- Use the provided signing_secret
        _secret := _signing_secret;
    END IF;

    -- Generate HMAC signature using the determined secret
    _hmac_sig := hmac(_subject, _secret, _alg::TEXT);

    -- Encode the signature based on the specified encoding style
    IF _encoding = 'base64' THEN
        _encoded_sig := encode(_hmac_sig, 'base64');
    ELSE
        _encoded_sig := encode(_hmac_sig, 'hex');
    END IF;

    -- Return the signature with or without a prefix
    IF _style = 'HMAC_WITH_PREFIX' THEN
        RETURN _alg::TEXT || '=' || _encoded_sig;
    ELSE
        RETURN _encoded_sig;
    END IF;
END;
$$ LANGUAGE plpgsql;

--
-- TRIGGER BEFORE a record is inserted in pgqueue.job_queue
-- This will:
--  1) Make sure the job should run now, if not divert to later
--  2) Sets job_status to 'processing' and last_at to now() if it runs it
--  3) Creates the signature header if one is requested and stores it
--  4) Processes the job for the first time
-- Sice it is a BEFORE trigger, it returns modified NEW with the correct
-- data based on the processing it did.
--
CREATE OR REPLACE FUNCTION pgqueue.process_new_job()
RETURNS TRIGGER
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
    _request_id BIGINT;
    _params TEXT;
    _sql TEXT;
    _schema_name TEXT;
    _func_name TEXT;
BEGIN
    RAISE LOG 'Processing job_id: %', NEW.job_id;

    -- create signature if required
    IF NEW.signing_secret IS NOT NULL OR NEW.signing_vault IS NOT NULL THEN
        -- create signature and add to headers
        NEW.headers :=
            jsonb_build_object(
                COALESCE(NEW.signing_header, 'X-HMAC-Signature'),
                pgqueue.create_signature(
                    NEW.payload::TEXT::BYTEA,
                    NEW.signing_secret,
                    NEW.signing_vault,
                    NEW.signing_style,
                    NEW.signing_alg,
                    NEW.signing_enc
                ) 
            ) || NEW.headers;
    END IF;

    -- check if job_jwt is from_session and if so get the right jwt
    IF NEW.job_jwt = 'from_session' THEN
        -- Get the JWT from the Authorization header in the request
        NEW.job_jwt := current_setting('request.headers', true)::json->>'authorization';

        -- Verify that the Authorization header was found
        IF NEW.job_jwt IS NULL THEN
            RAISE EXCEPTION 'Authorization header not found in the request but jwt set to from_session!';
        END IF;
        
        -- Remove 'Bearer ' prefix if it exists
        IF LEFT(NEW.job_jwt, 7) = 'Bearer ' THEN
            NEW.job_jwt := substr(NEW.job_jwt, 8);
        END IF;
    END IF;

    -- check if we are supposed to run this job already
    IF NEW.run_at > now() THEN
        RETURN NEW;
    END IF;

    -- set our job_status to processing
    NEW.job_status := 'processing';
    NEW.last_at := now();

    -- Check the job type and execute accordingly
    IF (NEW.job_type = 'FUNC') THEN
        -- Build schema.function
        IF position('.' IN NEW.url) > 0 THEN
            -- split
            _schema_name := split_part(NEW.url, '.', 1);
            _func_name := split_part(NEW.url, '.', 2);
        ELSE
            -- no schema, default to "public"
            _schema_name := 'public';
            _func_name := NEW.url;
        END IF;

        -- Extract and build params for call from payload
        _params := string_agg(
            format('%I := %L', key, value),
            ', '
        ) FROM jsonb_each_text(NEW.payload);

        -- Build the final SQL to execute
        _sql := format('SELECT %I.%I(%s)', _schema_name, _func_name, _params);

        -- Execute and store result
        EXECUTE _sql INTO NEW.response_content;

        -- Set job as done
        NEW.job_status := 'completed';
    ELSE
        -- Call the request_wrapper to process the job
        _request_id := pgqueue.request_wrapper(
            _method := NEW.job_type,
            _url := NEW.url,
            _jwt := NEW.job_jwt,
            _body := NEW.payload,
            _headers := NEW.headers
        );

        -- store the request_id for later
        INSERT INTO pgqueue.executed_requests (request_id, job_id)
        VALUES (_request_id, NEW.job_id);
    END IF;

    -- return final job for insert
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Add the trigger to the queue table:
CREATE TRIGGER process_new_job_trigger
BEFORE INSERT ON pgqueue.job_queue
FOR EACH ROW
EXECUTE FUNCTION pgqueue.process_new_job();

--
-- Process jobs flagged as failed OR new, keeping account for run_at field!
--
CREATE OR REPLACE FUNCTION pgqueue.process_scheduled_jobs()
RETURNS void
SECURITY DEFINER
SET search_path TO ''
AS $$
DECLARE
    _r RECORD;
    _request_id BIGINT;
    _schema_name TEXT;
    _func_name TEXT;
    _result TEXT;
    _params TEXT;
    _sql TEXT;
BEGIN
    RAISE LOG 'Looking for failed or scheduled jobs';

    -- Look for all jobs either failed or new with a low enough retry_count and run_at
    FOR _r IN (
            SELECT job_id, job_type, url, job_jwt, payload, headers, retry_count FROM pgqueue.job_queue
            WHERE (
                (job_status = 'new') OR
                (job_status = 'failed' AND retry_count <= retry_limit)
            ) AND run_at <= NOW()
            FOR UPDATE SKIP LOCKED
    ) LOOP
        RAISE LOG 'Running job_id: %', _r.job_id;

        IF _r.job_type = 'FUNC' THEN
            -- Build schema.function
            IF position('.' IN _r.url) > 0 THEN
                -- split
                _schema_name := split_part(_r.url, '.', 1);
                _func_name := split_part(_r.url, '.', 2);
            ELSE
                -- no schema, default to "public"
                _schema_name := 'public';
                _func_name := _r.url;
            END IF;

            -- Extract and build params for call from payload
            _params := string_agg(
                format('%I := %L', key, value),
                ', '
            ) FROM jsonb_each_text(_r.payload);

            -- Build the final SQL to execute
            _sql := format('SELECT %I.%I(%s)', _schema_name, _func_name, _params);

            -- Execute and store result
            EXECUTE _sql INTO _result;

            -- Set job as done and set _result
            UPDATE pgqueue.job_queue SET
                job_status = 'completed',
                response_content = _result,
                response_status = 200 -- Assuming success
            WHERE job_id = _r.job_id;
        ELSE
            -- Call the request_wrapper to process the job
            _request_id := pgqueue.request_wrapper(
                _method := _r.job_type,
                _url := _r.url,
                _jwt := _r.job_jwt,
                _body := _r.payload,
                _headers := _r.headers
            );
            INSERT INTO pgqueue.executed_requests (request_id, job_id)
            VALUES (_request_id, _r.job_id);
        END IF;
    END LOOP;
-- Just in case we have an exception somewhere, log it and fail the job
EXCEPTION
    WHEN OTHERS THEN
        RAISE LOG 'Error processing job_id: %', _r.job_id;
        -- Handle failure and potentially retry or mark as too_many retries
        IF _r.retry_count + 1 > _r.retry_limit THEN
            UPDATE pgqueue.job_queue
                SET job_status = 'too_many',
                    last_at = NOW(),
                    retry_count = retry_count + 1,
                    response_status = 0,
                    response_content = SQLERRM
                WHERE job_id = _r.job_id;
        ELSE
            UPDATE pgqueue.job_queue
                SET job_status = 'failed',
                    last_at = NOW(),
                    retry_count = retry_count + 1,
                    run_at = now() + 
                        INTERVAL '1 second' * 
                        ROUND((POWER(2, retry_count) * (10-(retry_count/1.5)))/2),
                    response_status = 0,
                    response_content = SQLERRM
                WHERE job_id = _r.job_id;
        END IF;

        -- Log the error in our failed_log too
        INSERT INTO pgqueue.failed_log
            (job_id, job_run, response_status, response_content)
        VALUES
            (_r.job_id, _r.retry_count+1, 0, SQLERRM);
END;
$$ LANGUAGE plpgsql;


--
-- Convenience function around pg_net:
--
CREATE OR REPLACE FUNCTION pgqueue.request_wrapper(
    _method pgqueue.job_type,
    _url TEXT,
    _jwt TEXT,
    _params JSONB DEFAULT '{}'::JSONB,
    _body JSONB DEFAULT '{}'::JSONB,
    _headers JSONB DEFAULT '{}'::JSONB
)
RETURNS BIGINT
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
    _request_id BIGINT;
    _timeout INT;
    _api_key TEXT;
    _base_url TEXT;
    _full_url TEXT;
    _full_headers JSONB;
BEGIN
    _timeout := 2000;

    -- If _url starts with / then we just have a path and use the _base_url
    -- This means the system assumes we are calling a supabase edge function!
    -- Resulting in Authorization header being set by us
    IF LEFT(_url, 1) = '/' THEN
        -- Determine the API key to use for authorization
        IF _jwt IS NULL THEN
            -- No jwt provided, get the service_role from the vault
            SELECT 'Bearer ' || decrypted_secret INTO _api_key
            FROM vault.decrypted_secrets
            WHERE name = 'service_role';
        ELSE
            -- Use the JWT provided in the job_queue
            _api_key := 'Bearer ' || _jwt;
        END IF;

        -- Get the consumer function URL
        SELECT decrypted_secret INTO _base_url
        FROM vault.decrypted_secrets
        WHERE name = 'consumer_edge_base';

        _full_url := _base_url || _url;
        _full_headers := jsonb_build_object(
                'Authorization', _api_key, 
                'Content-Type', 'application/json'
            ) || _headers;
    ELSE
        _full_url := _url;
        _full_headers := jsonb_build_object(
                'Content-Type', 'application/json'
            ) || _headers;
    END IF;

    -- Perform the appropriate HTTP request based on the method
    IF _method = 'DELETE' THEN
        SELECT net.http_delete(
            url := _full_url,
            params := _params,
            headers := _full_headers,
            timeout_milliseconds := _timeout
        ) INTO _request_id;
    ELSIF _method = 'POST' THEN
        SELECT net.http_post(
            url := _full_url,
            body := _body,
            params := _params,
            headers := _full_headers,
            timeout_milliseconds := _timeout
        ) INTO _request_id;
    ELSIF _method = 'GET' THEN
        SELECT net.http_get(
            url := _full_url,
            params := _params,
            headers := _full_headers,
            timeout_milliseconds := _timeout
        ) INTO _request_id;
    ELSE
        RAISE EXCEPTION 'Method must be DELETE, POST, or GET';
    END IF;

    RETURN _request_id;
END;
$$ LANGUAGE plpgsql;

--
-- Helper function to use pgqueue to trigger webhooks from
-- postgresql triggers. Always uses POST!
--
CREATE OR REPLACE FUNCTION pgqueue.trigger_webhook()
RETURNS TRIGGER
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
    _url TEXT;
    _headers JSONB := '{}';
    _jwt TEXT := NULL;
    _signing_secret BYTEA := NULL;
    _signing_vault TEXT := NULL;
    _signing_header TEXT := NULL;
    _signing_style pgqueue.signing_styles := NULL;
    _signing_alg pgqueue.signing_algs := 'sha256';
    _signing_enc pgqueue.signing_encs := 'hex';
    _payload JSONB;
BEGIN
    -- Retrieve the function arguments via TG_NARGS and TG_ARGV
    IF TG_NARGS >= 1 THEN
        _url := TG_ARGV[0];
    ELSE
        RAISE EXCEPTION 'URL argument is required';
    END IF;

    IF TG_NARGS >= 2 THEN
        _headers := TG_ARGV[1]::jsonb;
    END IF;

    IF TG_NARGS >= 3 THEN
        _jwt := TG_ARGV[2];
    END IF;

    IF TG_NARGS >= 4 THEN
        _signing_secret := TG_ARGV[3]::bytea;
    END IF;

    IF TG_NARGS >= 5 THEN
        _signing_vault := TG_ARGV[4];
    END IF;

    IF TG_NARGS >= 6 THEN
        _signing_header := TG_ARGV[5];
    END IF;

    IF TG_NARGS >= 7 THEN
        _signing_style := TG_ARGV[6]::pgqueue.signing_styles;
    END IF;

    IF TG_NARGS >= 8 THEN
        _signing_alg := TG_ARGV[7]::pgqueue.signing_algs;
    END IF;

    IF TG_NARGS >= 9 THEN
        _signing_enc := TG_ARGV[8]::pgqueue.signing_encs;
    END IF;

    -- Build the payload based on the trigger event
    IF TG_OP = 'INSERT' THEN
        _payload := jsonb_build_object(
            'type', 'INSERT',
            'table', TG_TABLE_NAME,
            'schema', TG_TABLE_SCHEMA,
            'record', row_to_json(NEW)
        );
    ELSIF TG_OP = 'UPDATE' THEN
        _payload := jsonb_build_object(
            'type', 'UPDATE',
            'table', TG_TABLE_NAME,
            'schema', TG_TABLE_SCHEMA,
            'old_record', row_to_json(OLD),
            'record', row_to_json(NEW)
        );
    ELSIF TG_OP = 'DELETE' THEN
        _payload := jsonb_build_object(
            'type', 'DELETE',
            'table', TG_TABLE_NAME,
            'schema', TG_TABLE_SCHEMA,
            'old_record', row_to_json(OLD)
        );
    ELSE
        -- If somehow called for other operation, raise an exception
        RAISE EXCEPTION 'Unsupported trigger operation: %', TG_OP;
    END IF;

    -- Insert a new job into the job_queue table for the webhook call
    INSERT INTO pgqueue.job_queue (
        url,
        job_type,
        job_jwt,
        payload,
        headers,
        signing_secret,
        signing_vault,
        signing_header,
        signing_style,
        signing_alg,
        signing_enc
    ) VALUES (
        _url,
        'POST',
        _jwt,
        _payload,
        _headers,
        _signing_secret,
        _signing_vault,
        _signing_header,
        _signing_style,
        _signing_alg,
        _signing_enc
    );

    -- RETURN OLD on DELETE triggers and NEW on any other trigger.
    IF TG_OP = 'DELETE' THEN
        RETURN OLD;
    ELSE
        RETURN NEW;
    END IF;
END;
$$ LANGUAGE plpgsql;

--
-- Helper function to use in pg_cron to process tasks every 20 seconds
--
CREATE OR REPLACE FUNCTION pgqueue.process_job_results_subminute()
RETURNS void
SECURITY DEFINER
SET search_path TO ''
AS $$
BEGIN
  -- Call process_tasks() with 20 seconds between each call
  PERFORM pgqueue.process_job_results_if_unlocked();
  PERFORM pg_sleep(20);
  PERFORM pgqueue.process_job_results_if_unlocked();
  PERFORM pg_sleep(20);
  PERFORM pgqueue.process_job_results_if_unlocked();
END;
$$ LANGUAGE plpgsql;

ALTER TABLE pgqueue.executed_requests ENABLE ROW LEVEL SECURITY;
ALTER TABLE pgqueue.job_queue ENABLE ROW LEVEL SECURITY;
ALTER TABLE pgqueue.workers ENABLE ROW LEVEL SECURITY;
ALTER TABLE pgqueue.failed_log ENABLE ROW LEVEL SECURITY;

grant all on schema pgqueue to postgres;
grant all on all tables in schema pgqueue to postgres;

